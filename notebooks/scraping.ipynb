{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather website web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "While a lot of local weather data is accessible on the internet, it is often sparse and not easily downloadable. \n",
    "Here we have a specific weather station, the data of which is only accesible day by day. In order to get it for a whole year or more, scraping seems to be the fastest solution.\n",
    "\n",
    "## Implementation\n",
    "We use the web-scraping library BeautifulSoup4, and lxml as a parser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import bs4 as BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suivi_meteo import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure\n",
    "For each day the website offers a table with a timestamp (hourly step), its temperature and rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time span for which we collect data.\n",
    "# Here for example one week\n",
    "origin = pd.Timestamp('20230101')\n",
    "enddate = pd.Timestamp('20230107')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas time range definition\n",
    "dti = pd.date_range(origin, date.today(), freq=\"d\")\n",
    "\n",
    "# Output dataframe definition\n",
    "output = pd.DataFrame({\"time\":[], \"temperature\":[], \"precipitations\":[]})\n",
    "\n",
    "# \n",
    "for index in range(len(dti)):\n",
    "    print(dti[index])\n",
    "    url = functions.url_from_datetime(dti[index])\n",
    "    soup = functions.soup_from_url(url)\n",
    "    # Let's access the table \n",
    "    tablesoup = soup.find(string='locale').parent.parent.parent.parent\n",
    "    uglydf = functions.dataframe_from_soup(tablesoup)\n",
    "    df = functions.dataframe_cleanup(uglydf, dti[index])\n",
    "    output = pd.concat([output, df],axis=0)\n",
    "\n",
    "# Output conservation as csv\n",
    "path = \"../results/meteo_\" + str(origin.year) + str(origin.month) + str(origin.day) + '_' + str(enddate.year)+str(origin.month)+str(origin.day)\n",
    "output.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat\n",
    "It should be noted that this method is poorly replicable to other websites, and that the data cleaning function must be adaptated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
